# -*- coding: utf-8 -*-
"""WineQualityPrediciton.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E5k_0W7p5p3YmYkzVWtfFkvM_6F_iEcQ
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline


red=pd.read_csv('F:\wine.html\wineQualityReds.csv')

red.head(10)

red.info()

red.isna().sum()

red.dtypes

plt.figure(figsize=(30,20))
corr=red.corr()
sns.heatmap(corr,annot=True)
plt.show()

custom_colors = ["#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd", "#8c564b"]

ig = plt.figure(figsize = (10,6))
sns.barplot(x = 'quality', y = 'fixed.acidity', hue='quality', data=red, palette=custom_colors, dodge=False, legend=False)

fig = plt.figure(figsize = (10,6))
sns.barplot(x='quality', y='volatile.acidity', hue='quality', data=red, palette=custom_colors, dodge=False, legend=False)

fig = plt.figure(figsize = (10,6))
sns.barplot(x = 'quality', y = 'citric.acid', hue='quality', data=red, palette=custom_colors, dodge=False, legend=False)

fig = plt.figure(figsize = (10,6))
sns.barplot(x = 'quality', y = 'residual.sugar', hue='quality', data=red, palette=custom_colors, dodge=False, legend=False)

fig = plt.figure(figsize = (10,6))
sns.barplot(x = 'quality', y = 'chlorides', hue='quality', data=red, palette=custom_colors, dodge=False, legend=False)

fig = plt.figure(figsize = (10,6))
sns.barplot(x = 'quality', y = 'free.sulfur.dioxide', hue='quality', data=red, palette=custom_colors, dodge=False, legend=False)

fig = plt.figure(figsize = (10,6))
sns.barplot(x = 'quality', y = 'total.sulfur.dioxide', hue='quality', data=red, palette=custom_colors, dodge=False, legend=False)

fig = plt.figure(figsize = (10,6))
sns.barplot(x = 'quality', y = 'sulphates', hue='quality', data=red, palette=custom_colors, dodge=False, legend=False)
plt.show()

fig = plt.figure(figsize = (10,6))
sns.barplot(x = 'quality', y = 'alcohol', hue='quality', data=red, palette=custom_colors, dodge=False, legend=False)
plt.show()

#Pre Processing
bins = (2, 6.5, 8)
group_names = ['bad', 'good']
red['quality'] = pd.cut(red['quality'], bins = bins, labels = group_names)

X = red.drop('quality', axis=1)
y = red['quality']

#assign a labels to our quality variable
from sklearn.preprocessing import LabelEncoder
label_quality = LabelEncoder()
red['quality'] = label_quality.fit_transform(red['quality'])
red['quality'].value_counts()

plt.figure(figsize=(8, 6))
sns.countplot(x='quality', hue='quality', data=red, palette=custom_colors, dodge=False, legend=False)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report,confusion_matrix
rfc = RandomForestClassifier(n_estimators=200)
rfc.fit(X_train, y_train)
pred_rfc = rfc.predict(X_test)
print(classification_report(y_test, pred_rfc))

print(confusion_matrix(y_test, pred_rfc))

from sklearn.metrics import accuracy_score
acc=accuracy_score(y_test,pred_rfc)
print(acc)

from sklearn.svm import SVC
svc = SVC()
svc.fit(X_train, y_train)
pred_svc = svc.predict(X_test)
print(classification_report(y_test, pred_svc))

print(confusion_matrix(y_test, pred_svc))

from sklearn.metrics import accuracy_score
acc=accuracy_score(y_test,pred_svc)
print(acc)

from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report
nb = GaussianNB()
nb.fit(X_train, y_train)
pred_nb = nb.predict(X_test)
print(classification_report(y_test, pred_nb))

print(confusion_matrix(y_test, pred_nb))

from sklearn.metrics import accuracy_score
acc=accuracy_score(y_test,pred_nb)
print(acc)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
lr = LinearRegression()
lr.fit(X_train, y_train)
pred_lr = lr.predict(X_test)
print('Mean Squared Error:', mean_squared_error(y_test, pred_lr))
print('R2 Score:', r2_score(y_test, pred_lr))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
log_reg = LogisticRegression()
log_reg.fit(X_train, y_train)
pred_log_reg = log_reg.predict(X_test)
print(classification_report(y_test, pred_log_reg))

print(confusion_matrix(y_test, pred_log_reg))

from sklearn.metrics import accuracy_score
acc=accuracy_score(y_test,pred_log_reg)
print(acc)

from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import classification_report
ada = AdaBoostClassifier()
ada.fit(X_train, y_train)
pred_ada = ada.predict(X_test)
print(classification_report(y_test, pred_ada))

print(confusion_matrix(y_test, pred_ada))

from sklearn.metrics import accuracy_score
acc=accuracy_score(y_test,pred_ada)
print(acc)

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import classification_report
gbc = GradientBoostingClassifier()
gbc.fit(X_train, y_train)
pred_gbc = gbc.predict(X_test)
print(classification_report(y_test, pred_gbc))

print(confusion_matrix(y_test, pred_gbc))

from sklearn.metrics import accuracy_score
acc=accuracy_score(y_test,pred_gbc)
print(acc)

import pickle
pickle.dump(rfc,open('pipe.pkl','wb'))
import sklearn
print(sklearn.__version__)